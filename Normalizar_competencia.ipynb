{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5untUeBaq/XoCFp6TfYbC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antoniosfn/-4-operations-calculator/blob/main/Normalizar_competencia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Google Colab: Normalização + Adicionar ID + Mesclar múltiplos CSVs únicos em MAIÚSCULAS"
      ],
      "metadata": {
        "id": "XXO7mYQebrNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q openpyxl\n",
        "\n",
        "import io, csv\n",
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# -------------------------\n",
        "# Utilitárias\n",
        "# -------------------------\n",
        "def drop_all_empty_columns(df):\n",
        "    \"\"\"\n",
        "    Remove colunas cujo conteúdo é vazio/NaN em todas as linhas.\n",
        "    Considera vazio se NaN ou string vazia após strip.\n",
        "    \"\"\"\n",
        "    cols_to_keep = []\n",
        "    for col in df.columns:\n",
        "        ser = df[col]\n",
        "        all_empty = True\n",
        "        for v in ser:\n",
        "            if pd.isna(v):\n",
        "                continue\n",
        "            if str(v).strip() == '':\n",
        "                continue\n",
        "            all_empty = False\n",
        "            break\n",
        "        if not all_empty:\n",
        "            cols_to_keep.append(col)\n",
        "    return df.loc[:, cols_to_keep].copy()\n",
        "\n",
        "def pick_name_column(df):\n",
        "    \"\"\"\n",
        "    Detecta a melhor coluna para 'nome'. Prioriza:\n",
        "    unique_names_per_row, name, nome  (case-insensitive), depois primeira textual, depois primeira.\n",
        "    \"\"\"\n",
        "    lower_map = {c.lower(): c for c in df.columns}\n",
        "    for prefer in ('unique_names_per_row','name','nome'):\n",
        "        if prefer in lower_map:\n",
        "            return lower_map[prefer]\n",
        "    for c in df.columns:\n",
        "        if pd.api.types.is_string_dtype(df[c]) or pd.api.types.is_object_dtype(df[c]):\n",
        "            return c\n",
        "    return df.columns[0]\n",
        "\n",
        "def split_and_unique_str(cell, sep=';'):\n",
        "    \"\"\"Separa por sep, strip, remove vazios e duplicatas, retorna '; ' join.\"\"\"\n",
        "    if pd.isna(cell):\n",
        "        return ''\n",
        "    s = str(cell)\n",
        "    parts = [p.strip() for p in s.split(sep)]\n",
        "    parts = [p for p in parts if p != '']\n",
        "    seen = set()\n",
        "    unique = []\n",
        "    for p in parts:\n",
        "        if p not in seen:\n",
        "            seen.add(p)\n",
        "            unique.append(p)\n",
        "    return '; '.join(unique)\n",
        "\n",
        "def robust_read_csv_from_bytes(b, enc_candidates=('utf-8-sig','utf-8','latin1')):\n",
        "    \"\"\"\n",
        "    Lê bytes CSV com tentativas múltiplas de encoding e delimitador.\n",
        "    Retorna DataFrame ou lança ValueError.\n",
        "    \"\"\"\n",
        "    last_err = None\n",
        "    for enc in enc_candidates:\n",
        "        try:\n",
        "            text = b.decode(enc)\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "            continue\n",
        "\n",
        "        sample = text[:8192]\n",
        "        # tentar sniff\n",
        "        try:\n",
        "            dialect = csv.Sniffer().sniff(sample, delimiters=[',',';','\\t','|'])\n",
        "            delim = dialect.delimiter\n",
        "            try:\n",
        "                df = pd.read_csv(io.StringIO(text), sep=delim, engine='c')\n",
        "                return df\n",
        "            except Exception:\n",
        "                try:\n",
        "                    df = pd.read_csv(io.StringIO(text), sep=delim, engine='python')\n",
        "                    return df\n",
        "                except Exception as e2:\n",
        "                    last_err = e2\n",
        "        except Exception as sniff_err:\n",
        "            last_err = sniff_err\n",
        "\n",
        "        # tentativas explícitas\n",
        "        for sep_try in [';', ',', '\\t', '|']:\n",
        "            try:\n",
        "                df = pd.read_csv(io.StringIO(text), sep=sep_try, engine='c')\n",
        "                return df\n",
        "            except Exception as e:\n",
        "                last_err = e\n",
        "                try:\n",
        "                    df = pd.read_csv(io.StringIO(text), sep=sep_try, engine='python')\n",
        "                    return df\n",
        "                except Exception as e2:\n",
        "                    last_err = e2\n",
        "\n",
        "        # fallback final para esse encoding\n",
        "        try:\n",
        "            df = pd.read_csv(io.StringIO(text), sep=None, engine='python')\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "\n",
        "    raise ValueError(\"Não foi possível interpretar o CSV com as estratégias tentadas. Último erro: \" + repr(last_err))\n",
        "\n",
        "# -------------------------\n",
        "# Fluxo principal\n",
        "# -------------------------\n",
        "print(\"Escolha uma opção:\")\n",
        "print(\"1 - Ler .xlsx, normalizar (gera normalized_name_only.csv com coluna 'nome')\")\n",
        "print(\"2 - Ler normalized_name_only.csv, adicionar ID (gera csv_with_id_and_name.csv com colunas 'id','nome')\")\n",
        "print(\"3 - Ler múltiplos .csv, mesclar únicos em MAIÚSCULAS (gera unique_merged_uppercase.csv com coluna 'nome')\")\n",
        "\n",
        "_mode = input(\"Digite 1, 2 ou 3 e pressione Enter: \").strip()\n",
        "if _mode not in ('1','2','3'):\n",
        "    print(\"Entrada inválida. Usando opção 1 por padrão.\")\n",
        "    _mode = '1'\n",
        "\n",
        "# -------------------------\n",
        "# Opção 1: XLSX -> normalized_name_only.csv (coluna 'nome')\n",
        "# -------------------------\n",
        "if _mode == '1':\n",
        "    print(\"\\n== Opção 1: upload do .xlsx ==\")\n",
        "    print(\"Envie o arquivo .xlsx agora.\")\n",
        "    uploaded = files.upload()\n",
        "    if not uploaded:\n",
        "        raise SystemExit(\"Nenhum arquivo enviado. Abortando.\")\n",
        "\n",
        "    # encontrar primeiro arquivo Excel\n",
        "    xlsx_file = None\n",
        "    for f in uploaded.keys():\n",
        "        if f.lower().endswith(('.xlsx','.xlsm','.xls')):\n",
        "            xlsx_file = f\n",
        "            break\n",
        "    if xlsx_file is None:\n",
        "        raise SystemExit(\"Nenhum arquivo Excel (.xlsx/.xlsm/.xls) encontrado no upload.\")\n",
        "\n",
        "    df = pd.read_excel(io.BytesIO(uploaded[xlsx_file]), engine='openpyxl')\n",
        "    print(f\"[OK] Arquivo carregado: {xlsx_file} — shape: {df.shape}\")\n",
        "\n",
        "    # remover colunas vazias\n",
        "    df = drop_all_empty_columns(df)\n",
        "    print(f\"[OK] Após remover colunas vazias — shape: {df.shape}\")\n",
        "\n",
        "    # detectar coluna de nomes\n",
        "    chosen_col = pick_name_column(df)\n",
        "    print(f\"[OK] Coluna escolhida: '{chosen_col}'\")\n",
        "\n",
        "    # normalizar para coluna 'nome'\n",
        "    df['nome'] = df[chosen_col].apply(lambda x: split_and_unique_str(x, sep=';'))\n",
        "\n",
        "    # manter apenas 1 coluna: nome\n",
        "    df_out = df[['nome']].copy()\n",
        "\n",
        "    out_name = \"normalized_name_only.csv\"\n",
        "    df_out.to_csv(out_name, index=False, encoding='utf-8-sig')\n",
        "    print(f\"[OK] Exportado: {out_name} (contém coluna 'nome')\")\n",
        "    files.download(out_name)\n",
        "    display(df_out.head(20))\n",
        "\n",
        "# -------------------------\n",
        "# Opção 2: normalized_name_only.csv -> csv_with_id_and_name.csv (colunas 'id','nome')\n",
        "# -------------------------\n",
        "if _mode == '2':\n",
        "    print(\"\\n== Opção 2: upload do .csv já normalizado ==\")\n",
        "    print(\"Envie o arquivo normalized_name_only.csv (ou equivalente).\")\n",
        "    uploaded = files.upload()\n",
        "    if not uploaded:\n",
        "        raise SystemExit(\"Nenhum arquivo enviado. Abortando.\")\n",
        "\n",
        "    # escolher primeiro CSV\n",
        "    csv_file = None\n",
        "    for f in uploaded.keys():\n",
        "        if f.lower().endswith('.csv'):\n",
        "            csv_file = f\n",
        "            break\n",
        "    if csv_file is None:\n",
        "        csv_file = list(uploaded.keys())[0]\n",
        "    print(f\"[INFO] Lendo: {csv_file}\")\n",
        "\n",
        "    try:\n",
        "        df = robust_read_csv_from_bytes(uploaded[csv_file])\n",
        "    except Exception as e:\n",
        "        raise SystemExit(f\"Falha ao ler CSV: {e}\")\n",
        "\n",
        "    print(f\"[OK] CSV lido — shape: {df.shape}\")\n",
        "\n",
        "    # remover colunas vazias\n",
        "    df = drop_all_empty_columns(df)\n",
        "    print(f\"[OK] Após remover colunas vazias — shape: {df.shape}\")\n",
        "\n",
        "    # detectar coluna de nomes\n",
        "    name_col = pick_name_column(df)\n",
        "    print(f\"[OK] Usando coluna '{name_col}' como fonte de nomes.\")\n",
        "\n",
        "    # normalizar a coluna nome (garantir formato consistente)\n",
        "    df['nome'] = df[name_col].apply(lambda x: split_and_unique_str(x, sep=';'))\n",
        "\n",
        "    # pedir start_id\n",
        "    while True:\n",
        "        sval = input(\"Digite o ID inicial (ex.: 124) e pressione Enter: \").strip()\n",
        "        try:\n",
        "            start_id = int(sval)\n",
        "            break\n",
        "        except:\n",
        "            print(\"Valor inválido. Digite um número inteiro.\")\n",
        "\n",
        "    # perguntar se atribuir IDs apenas às linhas não-vazias\n",
        "    apply_only_nonempty = input(\"Atribuir IDs apenas às linhas com 'nome' não vazia? (s/N): \").strip().lower() or 'n'\n",
        "\n",
        "    df = df.reset_index(drop=True)\n",
        "    if apply_only_nonempty.startswith('s'):\n",
        "        ids = [''] * len(df)\n",
        "        current = start_id\n",
        "        for i, val in enumerate(df['nome'].astype(str)):\n",
        "            if pd.isna(val) or str(val).strip() == '':\n",
        "                ids[i] = ''\n",
        "            else:\n",
        "                ids[i] = current\n",
        "                current += 1\n",
        "        df['id'] = ids\n",
        "        print(f\"[OK] IDs atribuídos apenas a linhas não-vazias, começando em {start_id}.\")\n",
        "    else:\n",
        "        df['id'] = [start_id + i for i in range(len(df))]\n",
        "        print(f\"[OK] IDs atribuídos a todas as linhas, começando em {start_id}.\")\n",
        "\n",
        "    # saída com no máximo 2 colunas: id, nome\n",
        "    df_out = df[['id', 'nome']].copy()\n",
        "    out_name = \"csv_with_id_and_name.csv\"\n",
        "    df_out.to_csv(out_name, index=False, encoding='utf-8-sig')\n",
        "    print(f\"[OK] Exportado: {out_name} (colunas: 'id','nome')\")\n",
        "    files.download(out_name)\n",
        "    display(df_out.head(20))\n",
        "\n",
        "# -------------------------\n",
        "# Opção 3: múltiplos CSVs -> unique_merged_uppercase.csv (coluna 'nome' em MAIÚSCULAS)\n",
        "# -------------------------\n",
        "if _mode == '3':\n",
        "    print(\"\\n== Opção 3: upload de múltiplos .csv ==\")\n",
        "    print(\"Selecione e envie todos os arquivos .csv que deseja mesclar (pode selecionar vários).\")\n",
        "    uploaded = files.upload()\n",
        "    if not uploaded:\n",
        "        raise SystemExit(\"Nenhum arquivo enviado. Abortando.\")\n",
        "\n",
        "    # coletar CSVs enviados\n",
        "    csv_keys = [k for k in uploaded.keys() if k.lower().endswith('.csv')]\n",
        "    if not csv_keys:\n",
        "        # se nenhum com .csv, tentar usar todos\n",
        "        csv_keys = list(uploaded.keys())\n",
        "\n",
        "    all_names = []\n",
        "    seen = set()\n",
        "    for k in csv_keys:\n",
        "        print(f\"[INFO] Lendo {k} ...\")\n",
        "        try:\n",
        "            df_tmp = robust_read_csv_from_bytes(uploaded[k])\n",
        "        except Exception as e:\n",
        "            print(f\"[AVISO] Falha ao ler {k}: {e}. Pulando.\")\n",
        "            continue\n",
        "\n",
        "        # remover colunas vazias\n",
        "        df_tmp = drop_all_empty_columns(df_tmp)\n",
        "\n",
        "        if df_tmp.shape[1] == 0:\n",
        "            print(f\"[AVISO] {k} não tem colunas não-vazias. Pulando.\")\n",
        "            continue\n",
        "\n",
        "        # detectar coluna de nomes\n",
        "        name_col = pick_name_column(df_tmp)\n",
        "        # extrair valores, separar por ';' (se houver), strip e uppercase\n",
        "        for cell in df_tmp[name_col].dropna().astype(str):\n",
        "            parts = [p.strip() for p in cell.split(';') if p.strip() != '']\n",
        "            for p in parts:\n",
        "                up = p.upper()\n",
        "                if up not in seen:\n",
        "                    seen.add(up)\n",
        "                    all_names.append(up)\n",
        "\n",
        "    if not all_names:\n",
        "        raise SystemExit(\"Nenhum nome único encontrado nos arquivos enviados.\")\n",
        "\n",
        "    df_out = pd.DataFrame({'nome': all_names})\n",
        "    out_name = \"unique_merged_uppercase.csv\"\n",
        "    df_out.to_csv(out_name, index=False, encoding='utf-8-sig')\n",
        "    print(f\"[OK] Exportado: {out_name} (total únicos: {len(all_names)}) — coluna 'nome' em MAIÚSCULAS\")\n",
        "    files.download(out_name)\n",
        "    display(df_out.head(50))\n",
        "\n",
        "print(\"\\nConcluído ✅\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dh9LTheGblWM",
        "outputId": "ec3a09d9-5fdd-4eb1-9604-0cc238247b6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Escolha uma opção:\n",
            "1 - Ler .xlsx, normalizar (gera normalized_name_only.csv com coluna 'nome')\n",
            "2 - Ler normalized_name_only.csv, adicionar ID (gera csv_with_id_and_name.csv com colunas 'id','nome')\n",
            "3 - Ler múltiplos .csv, mesclar únicos em MAIÚSCULAS (gera unique_merged_uppercase.csv com coluna 'nome')\n"
          ]
        }
      ]
    }
  ]
}